{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the final neural network \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' Ma', ' To', ' a ', ' an', ' au', ' be', ' ca', ' ch', ' co', ' da',\n",
       "       ...\n",
       "       'to ', 'ue ', 'un ', 'und', 'ur ', 'us ', 've ', 'you', 'Ã£o ', 'lang'],\n",
       "      dtype='object', length=198)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"ANN_features/train_50.csv\",index_col=0)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    \"Reformates data so it is appropriate for Tensorflow DNNC\"\n",
    "    x = df.drop(['lang'], axis=1)\n",
    "    x.columns = ['trigram_'+str(col) for col in list(range(len(x.columns)))]\n",
    "    y = df['lang']\n",
    "    y = y.map({\"eng\": 0, \"deu\": 1, \"spa\": 2, \"fra\": 3, \"por\": 4, \"ita\": 5})\n",
    "    return (x,y)\n",
    "\n",
    "def get_data(feat_type):\n",
    "    \"Gets the training, valid and test data bases for a specific feature type\"\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    \n",
    "    train = pd.read_csv(\"ANN_features/train_{}.csv\".format(feat_type),index_col=0)\n",
    "    train_norm = min_max_scaler.fit_transform(train.drop('lang', axis=1))\n",
    "    train_norm = pd.DataFrame(train_norm)\n",
    "    train_norm['lang'] = train['lang']\n",
    "    train_norm.columns = train.columns\n",
    "    \n",
    "    \n",
    "    valid = pd.read_csv(\"ANN_features/valid_{}.csv\".format(feat_type),index_col=0)\n",
    "    valid_norm = min_max_scaler.transform(valid.drop('lang', axis=1))\n",
    "    valid_norm = pd.DataFrame(valid_norm)\n",
    "    valid_norm['lang'] = valid['lang']\n",
    "    valid_norm.columns = valid.columns\n",
    "    \n",
    "    \n",
    "    \n",
    "    test = pd.read_csv(\"ANN_features/test_{}.csv\".format(feat_type),index_col=0)\n",
    "    test_norm = min_max_scaler.transform(test.drop('lang', axis=1))\n",
    "    test_norm = pd.DataFrame(test_norm)\n",
    "    test_norm['lang'] = test['lang']\n",
    "    test_norm.columns = test.columns\n",
    "    \n",
    "    #Use all data\n",
    "    \n",
    "    (train_x,train_y) = prepare_data(train)\n",
    "    (valid_x,valid_y) = prepare_data(valid)\n",
    "    (test_x,test_y) = prepare_data(test)\n",
    "    return (train_x,train_y), (valid_x,valid_y), (test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input functions \n",
    "def train_input_fn(features, labels, batch_size =100):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    # Return the dataset.\n",
    "    return dataset\n",
    "\n",
    "def eval_input_fn(features, labels, batch_size=100):\n",
    "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
    "    features=dict(features)\n",
    "    if labels is None:\n",
    "        # No labels, use only features.\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features, labels)\n",
    "\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\n",
    "    # Batch the examples\n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset\n",
    "\n",
    "#TensorFlow (2016) An Example of a DNNClassifier for the Iris dataset. [Source code]. WWW.tensorflow.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(hidden, steps):\n",
    "    \n",
    "    # Feature columns describe how to use the input.\n",
    "    my_feature_columns = []\n",
    "    for key in train_x.keys():\n",
    "        my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "        \n",
    "    my_checkpointing_config = tf.estimator.RunConfig(\n",
    "    save_checkpoints_secs = 30*60,  # Save checkpoints every 20 minutes.\n",
    "    keep_checkpoint_max = 2,       # Retain the 10 most recent checkpoints.\n",
    "    )\n",
    "\n",
    "    \"Fits a DNNC with the desired features and stores validation results \"\n",
    "    # Build a DNN.\n",
    "    classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 196 nodes each.\n",
    "    hidden_units=hidden,\n",
    "    # 6 languages.\n",
    "    n_classes=6,\n",
    "    config=my_checkpointing_config,\n",
    "    optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "      learning_rate=0.1,\n",
    "      l1_regularization_strength=0.001\n",
    "    ))\n",
    "    \n",
    "    # Train the Model.\n",
    "    classifier.train(\n",
    "    input_fn=lambda:train_input_fn(train_x, train_y),\n",
    "    steps=steps)\n",
    "    \n",
    "    #Get predictions of test values\n",
    "    predictions = list(classifier.predict(input_fn=lambda:eval_input_fn(test_x,labels=None)))\n",
    "\n",
    "    pred_y = []\n",
    "    for p in predictions:\n",
    "        pred_y.append(p['class_ids'][0])\n",
    "        \n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/conorosully/virtualenv/tensor/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210000 60000 30000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram_0</th>\n",
       "      <th>trigram_1</th>\n",
       "      <th>trigram_2</th>\n",
       "      <th>trigram_3</th>\n",
       "      <th>trigram_4</th>\n",
       "      <th>trigram_5</th>\n",
       "      <th>trigram_6</th>\n",
       "      <th>trigram_7</th>\n",
       "      <th>trigram_8</th>\n",
       "      <th>trigram_9</th>\n",
       "      <th>...</th>\n",
       "      <th>trigram_667</th>\n",
       "      <th>trigram_668</th>\n",
       "      <th>trigram_669</th>\n",
       "      <th>trigram_670</th>\n",
       "      <th>trigram_671</th>\n",
       "      <th>trigram_672</th>\n",
       "      <th>trigram_673</th>\n",
       "      <th>trigram_674</th>\n",
       "      <th>trigram_675</th>\n",
       "      <th>trigram_676</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 677 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trigram_0  trigram_1  trigram_2  trigram_3  trigram_4  trigram_5  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "2          0          0          0          0          0          1   \n",
       "3          0          0          0          0          0          0   \n",
       "4          0          0          0          0          0          0   \n",
       "\n",
       "   trigram_6  trigram_7  trigram_8  trigram_9     ...       trigram_667  \\\n",
       "0          0          0          0          0     ...                 0   \n",
       "1          0          0          0          0     ...                 0   \n",
       "2          0          0          0          0     ...                 0   \n",
       "3          0          0          0          0     ...                 0   \n",
       "4          0          0          0          0     ...                 0   \n",
       "\n",
       "   trigram_668  trigram_669  trigram_670  trigram_671  trigram_672  \\\n",
       "0            0            2            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   trigram_673  trigram_674  trigram_675  trigram_676  \n",
       "0            0            0            0            0  \n",
       "1            0            0            0            0  \n",
       "2            0            0            0            0  \n",
       "3            0            0            0            0  \n",
       "4            0            0            0            0  \n",
       "\n",
       "[5 rows x 677 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_x,train_y), (valid_x,valid_y),(test_x,test_y) = get_data('200')\n",
    "print(len(train_x),len(valid_x),len(test_x))\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/s2/82vv6ll16mn27w7gcdbccp3m0000gn/T/tmp5itwjqn8\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/s2/82vv6ll16mn27w7gcdbccp3m0000gn/T/tmp5itwjqn8', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 1800, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 2, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x125f77f28>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/s2/82vv6ll16mn27w7gcdbccp3m0000gn/T/tmp5itwjqn8/model.ckpt.\n",
      "INFO:tensorflow:loss = 173.999, step = 1\n",
      "INFO:tensorflow:global_step/sec: 9.81094\n",
      "INFO:tensorflow:loss = 11.941917, step = 101 (10.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6974\n",
      "INFO:tensorflow:loss = 9.287911, step = 201 (5.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7783\n",
      "INFO:tensorflow:loss = 5.529746, step = 301 (6.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4892\n",
      "INFO:tensorflow:loss = 7.971808, step = 401 (5.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.2749\n",
      "INFO:tensorflow:loss = 1.651495, step = 501 (5.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7259\n",
      "INFO:tensorflow:loss = 4.351406, step = 601 (5.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9453\n",
      "INFO:tensorflow:loss = 2.5701458, step = 701 (5.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.4208\n",
      "INFO:tensorflow:loss = 4.7944975, step = 801 (5.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.6865\n",
      "INFO:tensorflow:loss = 8.156661, step = 901 (5.654 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/s2/82vv6ll16mn27w7gcdbccp3m0000gn/T/tmp5itwjqn8/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.5009184.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/s2/82vv6ll16mn27w7gcdbccp3m0000gn/T/tmp5itwjqn8/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5094\n",
      "           1       1.00      1.00      1.00      5071\n",
      "           2       0.96      0.97      0.96      5004\n",
      "           3       0.99      0.98      0.99      4944\n",
      "           4       0.98      0.96      0.97      4960\n",
      "           5       0.98      0.98      0.98      4927\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     30000\n",
      "   macro avg       0.98      0.98      0.98     30000\n",
      "weighted avg       0.98      0.98      0.98     30000\n",
      "\n",
      "[[5058    4    9    7    6   10]\n",
      " [  10 5053    1    5    0    2]\n",
      " [  11    3 4867   14   72   37]\n",
      " [  22    5   17 4861   13   26]\n",
      " [   4    1  150    7 4772   26]\n",
      " [   6    3   42    9   15 4852]]\n"
     ]
    }
   ],
   "source": [
    "#Feature: 200 hidden layer: [339] steps:1000\n",
    "pred_y = fit_model([509],1000)\n",
    "print(classification_report(test_y,pred_y))\n",
    "print(confusion_matrix(test_y,pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5094\n",
      "           1       1.00      1.00      1.00      5071\n",
      "           2       0.96      0.97      0.96      5004\n",
      "           3       0.99      0.98      0.99      4944\n",
      "           4       0.98      0.96      0.97      4960\n",
      "           5       0.98      0.98      0.98      4927\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     30000\n",
      "   macro avg       0.98      0.98      0.98     30000\n",
      "weighted avg       0.98      0.98      0.98     30000\n",
      "\n",
      "[[5058    4    9    7    6   10]\n",
      " [  10 5053    1    5    0    2]\n",
      " [  11    3 4867   14   72   37]\n",
      " [  22    5   17 4861   13   26]\n",
      " [   4    1  150    7 4772   26]\n",
      " [   6    3   42    9   15 4852]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y,pred_y))\n",
    "print(confusion_matrix(test_y,pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann_test_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ann_test_result\n",
       "0                0\n",
       "1                2\n",
       "2                0\n",
       "3                0\n",
       "4                5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = pd.DataFrame()\n",
    "test_results['ann_test_result'] = pred_y\n",
    "print(len(pred_y))\n",
    "test_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.to_csv('ANN_features/ann_test_results_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # References \n",
    " TensorFlow (2016) An Example of a DNNClassifier for the Iris dataset. [Source code]. WWW.tensorflow.org"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
